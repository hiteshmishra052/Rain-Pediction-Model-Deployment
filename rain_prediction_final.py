# -*- coding: utf-8 -*-
"""Rain_Prediction_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oy94rDTrXgegd6BsbcuACw2iyJoFQEjX

# **1.The problem statement**

In this kernel, we will try to answer the question that whether or not it will rain tomorrow in Australia. We implement Logistic Regression with Python and Scikit-Learn.

To answer the question, we build a classifier to predict whether or not it will rain tomorrow in Australia. We train a binary classification model using Logistic Regression. I have used the Rain in Australia dataset for this project.

The dataset contains about 10 years of daily weather observations from many locations across Australia.

RainTomorrow is the target variable to predict. It means -- did it rain the next day, Yes or No? This column is Yes if the rain for that day was 1mm or more.

******

# **2. Import Libraries**
"""

import pandas as pd
import numpy as np
import missingno as msno
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, f1_score
import pickle
import warnings

warnings.filterwarnings('ignore')

"""# **3. Import Dataset**"""

df = pd.read_csv("C:/Users/HP/Desktop/Rain Prediction/weatherAUS.csv")

"""# **4. Exploratory data analysis**

* Step1 -  Import the data.

* Step2 -  Explore the data to gain insights about it.
"""

df.shape

"""**Preview the dataset**"""

df.head()

"""View Column Names"""

col_names = df.columns
col_names

"""Summary of the dataset"""

df.info()

"""Now we will view the statistical properties of dataset"""

df.describe(include='all')

df['RainTomorrow'].value_counts()

df['RainTomorrow'].isnull().sum()

"""# **5. Univariate Analysis**

* Explore Rain Tomorrow target variable

* Check for missing values
"""

df['RainTomorrow'].unique()

df.isnull().sum()

"""**Unique Values in each column**"""

df.nunique()

"""**Finding all the categorical and continuous values**"""

categorical_col,contin_val = [], []

for i in df.columns:

  if(df[i].dtypes == 'object'):
    categorical_col.append(i)
  else:
    contin_val.append(i)

print(categorical_col)
print(contin_val)

"""**Check Null Values**"""

df.isnull().sum()

msno.matrix(df)

msno.bar(df, sort = 'ascending')

msno.heatmap(df)

"""From the above graph we come to the conclusion that missing values are high in: Sunshine, Evaporation, Cloud3pm and Cloud9am.


"""

plt.figure(figsize=(17,15))
ax = sns.heatmap(df.corr(), square=True, annot=True, fmt='.2f')
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
plt.show()

"""* MinTemp and Temp9am highly correlated.
* MinTemp and Temp3pm highly correlated.
* MaxTemp and Temp9am highly correlated.
* MaxTemp and Temp3pm highly correlated.

* Temp3pm and Temp9am highly correlated.

* Humidity9am and Humidity3pm highly correlated.

**Mapping yes and no to 1 and 0 in some columns**
This is done so that the mean of RainTomorrow variable could be found out
"""

df['RainTomorrow'] = df['RainTomorrow'].map({'Yes':1,'No':0})
df['RainToday'] = df['RainToday'].map({'Yes':1,'No':0})

print(df['RainToday'])
print(df['RainTomorrow'])

"""**Dealing with the missing values**"""

(df.isnull().sum()/len(df))*100

#Filling the missing values for continuous variables with mode

# df['RainToday'] = df['RainToday'].fillna(df['RainToday'].mode()[0])
df['RainTomorrow'] = df['RainTomorrow'].fillna(df['RainTomorrow'].mode()[0])

#checking % of missing data in every column

(df.isnull().sum()/len(df))*100

df['RainTomorrow'].unique()

df['RainTomorrow'].isnull().sum()

"""**Data Visualization**

Count of rain today and tomorrow
"""

df['RainTomorrow'] = df['RainTomorrow'].map({1:'Yes',0:'No'})
df['RainToday'] = df['RainToday'].map({1:'Yes',0:'No'})

fig, ax = plt.subplots(1,2)
print(df['RainToday'].value_counts())
print(df['RainTomorrow'].value_counts())

plt.figure(figsize = (20,20))
sns.countplot(data = df, x = 'RainToday',ax=ax[0])
sns.countplot(data = df, x = 'RainTomorrow',ax = ax[1])

"""Viewing percentage of frequency of distribution of values"""

df['RainTomorrow'].value_counts()/len(df)

"""Interpretation"""

print(f"For the Rain Tomorrow Feature")
print(f"Yes is {0.780854*100}% times")
print(f"No is {0.219146*100}% times")

"""**Findings of Univariate Analysis**

* The two unique values in RainTomorrow are No and Yes.

* No of unique values in RainTomorrow  - 2.

* Out of the total no of RainTomorrow values,
    * No appears 78.0854% times
    * Yes appears 21.9146% times.

* The univariate plot confirms our findings that :-

  * The No variable have 113583 entries, and

  * The Yes variable have 31877 entries

# **6 . Bivariate Analysis**

Types of variables

Now we will segregate the dataset into categorical and numerical variables.

* Categorical values are of data type object
* Numerical values are of data type float64
"""

categorical =  [var for var in df.columns if df[var].dtype=='O']

print('There are {} categorical variables\n'.format(len(categorical)))

print('The categorical variables are :', categorical)

#View the categorical variables

df[categorical].head()

df[categorical].isnull().sum()

#view frequncy distribution of categorical variables

for var in categorical:
  print(df[var].value_counts()/np.float(len(df)))

# check for cardinality in categorical variables

for var in categorical:
  print(var, 'contains',len(df[var].unique()),'labels')

"""We can see that there is a **Date** variable which needs to be preprocessed.

So we will do preprocessing in Date variable

All the other variables contain relatively smaller number of variables

We will separate day month and year from the date variable

After that each one can be converted into int64

**Feature Engineering of Date Variable**
"""

df['Date'].dtypes

"""As the datatype of date column is object we need to convert this into datetime format"""

#parse the dates , currently coded as strings, into datetime format

df['Date'] = pd.to_datetime(df['Date'])
df['Date'].dtypes

#extract year from date

df['Year'] = df['Date'].dt.year

df['Year'].head()

#extract month from date

df['Month'] = df['Date'].dt.month

df['Month'].head()

#extract day from date

df['Day'] = df['Date'].dt.day

df['Day'].head()

#again view the summary of dataset

df.info()

#drop the original date variable

df = df.drop('Date',axis='columns')

#preview the dataset again

df.head()

"""Explore categorical variables one by one

"""

#find the categorical variables

categorical =  [var for var in df.columns if df[var].dtype=='O']

print('There are {} categorical variables\n'.format(len(categorical)))

print('The categorical variables are :', categorical)

#check for missing values in categorical variables

df[categorical].isnull().sum()

"""We can see that WindGustDir, WindDir9am, WindDir3pm, RainToday variables contain missing values. We will explore these variables one by one.

**Explore Location Variable**
"""

#print the no of labels in location variable

print('Location contains', len(df.Location.unique()),'labels')

#check labels in location variable

df.Location.unique()

#check the frequency distribution of values in Location variable

df['Location'].value_counts()

# let's do One Hot Encoding of Location variable
# get k-1 dummy variables after One Hot Encoding
# preview the dataset with head() method

pd.get_dummies(df.Location, drop_first = True).head()

"""**Explore WindGustDir variable**"""

#print number of labels in WindGustDir variable

print('WindGustDir contains',len(df['WindGustDir'].unique()),' labels')

#check the labels in WindGustDir variable

df['WindGustDir'].unique()

#check the frequncy distribution of values in WindGustDir variable

df.WindGustDir.value_counts()

# let's do One Hot Encoding of WindGustDir variable
# get k-1 dummy variables after One Hot Encoding
# also add an additional dummy variable to indicate there was missing data
# preview the dataset with head() method

pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True).head()

# sum the number of 1s per boolean variable over the rows of the dataset
# it will tell us how many observations we have for each category

pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True).sum(axis=0)

"""We can see that there are 10326 missing values in WindGustDir variable.

**Explore WindDir9am variable**
"""

#print number of labels in WindDir9am variable

print('WindDir9am contains', len(df['WindDir9am'].unique()), 'labels')

# check labels in WindDir9am variable

df['WindDir9am'].unique()

# check frequency distribution of values in WindDir9am variable

df['WindDir9am'].value_counts()

# let's do One Hot Encoding of WindDir9am variable
# get k-1 dummy variables after One Hot Encoding
# also add an additional dummy variable to indicate there was missing data
# preview the dataset with head() method

pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True).head()

# sum the number of 1s per boolean variable over the rows of the dataset
# it will tell us how many observations we have for each category

pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True).sum(axis=0)

"""**Explore WindDir3pm variable**"""

# print number of labels in WindDir3pm variable

print('WindDir3pm contains', len(df['WindDir3pm'].unique()), 'labels')

# checking labels in WindDir3pm variable

df['WindDir3pm'].unique()

# check frequency distribution of values in WindDir3pm variable

df['WindDir3pm'].value_counts()

# let's do One Hot Encoding of WindDir3pm variable
# get k-1 dummy variables after One Hot Encoding
# also add an additional dummy variable to indicate there was missing data
# preview the dataset with head() method

pd.get_dummies(df.WindDir3pm, drop_first=True, dummy_na=True).head()

# sum the number of 1s per boolean variable over the rows of the dataset
# it will tell us how many observations we have for each category

pd.get_dummies(df.WindDir3pm, drop_first=True, dummy_na=True).sum(axis=0)

"""**Explore RainToday variable**"""

# print number of labels in RainToday variable

print('RainToday contains', len(df['RainToday'].unique()), 'labels')

# check labels in WindGustDir variable

df['RainToday'].unique()

# check frequency distribution of values in WindGustDir variable

df.RainToday.value_counts()

# let's do One Hot Encoding of RainToday variable
# get k-1 dummy variables after One Hot Encoding
# also add an additional dummy variable to indicate there was missing data
# preview the dataset with head() method

pd.get_dummies(df.RainToday, dummy_na=True).head()

# sum the number of 1s per boolean variable over the rows of the dataset
# it will tell us how many observations we have for each category

pd.get_dummies(df.RainToday, dummy_na=True).sum(axis=0)

"""There are 3261 missing values

**Explore Numerical Variables**
"""

#find the numerical variables

numerical = [var for var in df.columns if df[var].dtype!='O']

print('There are {} numerical variables\n'.format(len(numerical)))

print('The numerical variables are:',numerical)

#view the numericalvariables

df[numerical].head()

"""**Summary of numerical variables**
* There are 16 numerical variables.
* These are  -  MinTemp, MaxTemp, Rainfall, Evaporation, Sunshine, WindGustSpeed, WindSpeed9am, WindSpeed3pm, Humidity9am, Humidity3pm, Pressure9am, Pressure3pm, Cloud9am, Cloud3pm, Temp9am and Temp3pm.
* All of the numerical variables are of continuous type

Now we will Explore the problems within numerical variables

Missing values in numerical variables
"""

# check missing values in numerical variables

df[numerical].isnull().sum()

"""We can see there are 16 numerical variables containing missing values

**Outliers in numerical variables**
"""

#view summary statics in numerical variables
print(round(df[numerical].describe()),2)

"""On closer inspection, we can see that the Rainfall, Evaporation, WindSpeed9am and WindSpeed3pm columns may contain outliers"""

#draw the boxplots to visualize outliers in the above variables

plt.figure(figsize=(15,10))

plt.subplot(2,2,1)
fig = df.boxplot(column='Rainfall')
fig.set_title('')
fig.set_ylabel('Rainfall')

plt.subplot(2,2,2)
fig = df.boxplot(column='Evaporation')
fig.set_title('')
fig.set_ylabel('Evaporation')

plt.subplot(2,2,3)
fig = df.boxplot(column = 'WindSpeed9am')
fig.set_title('')
fig.set_ylabel('WindSpeed9am')

plt.subplot(2,2,4)
fig = df.boxplot(column='WindSpeed3pm')
fig.set_title('')
fig.set_ylabel('WindSpeed3pm')

"""**Check the distribution of variables**

* Now, we will plot the histograms to check distributions to find out if they are normal or skewed.

* If the variable follows normal distribution, then we will do Extreme Value Analysis otherwise if they are skewed, we will find out IQR (Interquantile range).
"""

#plot the histogram to check the distribution

plt.figure(figsize=(15,10))

plt.subplot(2,2,1)
fig = df['Rainfall'].hist(bins=10)
fig.set_xlabel('Rainfall')
fig.set_ylabel('RainTomorrow')

plt.subplot(2,2,2)
fig = df['Evaporation'].hist(bins=10)
fig.set_xlabel('Evaporation')
fig.set_ylabel('RainTomorrow')

plt.subplot(2,2,3)
fig = df['WindSpeed9am'].hist(bins=10)
fig.set_xlabel('WindSpeed9am')
fig.set_ylabel('RainTomorrow')

plt.subplot(2,2,4)
fig = df['WindSpeed3pm'].hist(bins=10)
fig.set_xlabel('WindSpeed3pm')
fig.set_ylabel('RainTomorrow')

#find the oultiers for Rainfall Variable

Q1 = df['Rainfall'].describe()[4]
Q2 = df['Rainfall'].describe()[6]
IQR = Q2 - Q1
Lower_fence = Q1 - (IQR * 3)
Upper_fence = Q2 + (IQR * 3)
print('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))

df['Rainfall'].describe()

"""For Rainfall, the minimum and maximum values are 0.0 and 371.0. So, the outliers are values > 3.2."""

#find the oultiers for Evaporation Variable

Q1 = df['Evaporation'].describe()[4]
Q2 = df['Evaporation'].describe()[6]
IQR = Q2 - Q1
Lower_fence = Q1 - (IQR * 3)
Upper_fence = Q2 + (IQR * 3)
print('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))

df['Evaporation'].describe()

"""For Evaporation, the minimum and maximum values are 0.0 and 145.0. So, the outliers are values > 21.8."""

#find the oultiers for WindSpeed9am Variable

Q1 = df['WindSpeed9am'].describe()[4]
Q2 = df['WindSpeed9am'].describe()[6]
IQR = Q2 - Q1
Lower_fence = Q1 - (IQR * 3)
Upper_fence = Q2 + (IQR * 3)
print('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))

df['WindSpeed9am'].describe()

"""For WindSpeed9am, the minimum and maximum values are 0.0 and 130.0. So, the outliers are values > 55.0."""

#find the oultiers for WindSpeed3pm Variable

Q1 = df['WindSpeed3pm'].describe()[4]
Q2 = df['WindSpeed3pm'].describe()[6]
IQR = Q2 - Q1
Lower_fence = Q1 - (IQR * 3)
Upper_fence = Q2 + (IQR * 3)
print('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))

df['WindSpeed3pm'].describe()

"""For WindSpeed3pm, the minimum and maximum values are 0.0 and 87.0. So, the outliers are values > 57.0.

# **7.Multivariate Analysis**

* An important step in EDA is to discover patterns and relationships between variables in the dataset.

* We will use heat map and pair plot to discover the patterns and relationships in the dataset.

* First of all, We will draw a heat map.
"""

correlation = df.corr()

"""Heat Map"""

plt.figure(figsize = (16,12))
plt.title('Correlation HeatMap of Rain in Australia Dataset')
ax = sns.heatmap(correlation, square=True,annot=True,fmt='.2f',linecolor = 'white')
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
ax.set_yticklabels(ax.get_yticklabels(), rotation=30)
plt.show()

"""**Interpretation**
From the above correlation heat map, we can conclude that :-

* MinTemp and MaxTemp variables are highly positively correlated (correlation coefficient = 0.74).

* MinTemp and Temp3pm variables are also highly positively correlated (correlation coefficient = 0.71).

* MinTemp and Temp9am variables are strongly positively correlated (correlation coefficient = 0.90).

* MaxTemp and Temp9am variables are strongly positively correlated (correlation coefficient = 0.89).

* MaxTemp and Temp3pm variables are also strongly positively correlated (correlation coefficient = 0.98).

* WindGustSpeed and WindSpeed3pm variables are highly positively correlated (correlation coefficient = 0.69).

* Pressure9am and Pressure3pm variables are strongly positively correlated (correlation coefficient = 0.96).

* Temp9am and Temp3pm variables are strongly positively correlated (correlation coefficient = 0.86).

**Pair Plot**

First of all, I will define extract the variables which are highly positively correlated.
"""

num_var = ['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm', 'WindGustSpeed', 'WindSpeed3pm', 'Pressure9am', 'Pressure3pm']

"""Now, I will draw pairplot to depict relationship between these variables."""

sns.pairplot(df[num_var], kind='scatter', diag_kind='hist', palette='Rainbow')
plt.show()

"""**Interpretation**
* We have defined a variable num_var which consists of MinTemp, MaxTemp, Temp9am, Temp3pm, WindGustSpeed, WindSpeed3pm, Pressure9am and Pressure3pm variables.

* The above pair plot shows relationship between these variables.

# **8. Declare feature vector and target variable**
"""

X = df.drop(['RainTomorrow'],axis=1)

y = df['RainTomorrow']

"""# **9. Split data into separate training and test set**"""

# Split X and y into training and testing sets

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)

#check the shape of X_train and X_test

X_train.shape, X_test.shape

"""# **10. Feature Engineering**

* We will carry out feature engineering on different types of variables.

* First, We will display the categorical and numerical variables again separately.
"""

#check data types in X_train

X_train.dtypes

#display categorical variables

categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']

categorical

#display numerical variables

numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']

numerical

"""Engineering missing values in numerical variables"""

# check missing values in numerical variables in X_train

X_train[numerical].isnull().sum()

# check missing values in numerical variables in X_test

X_test[numerical].isnull().sum()

# print percentage of missing values in the numerical variables in training set

for col in numerical:
  if X_train[col].isnull().mean()>0:
    print(col, round(X_train[col].isnull().mean(),4))

"""**Assumption**
* We assume that the data are missing completely at random (MCAR). There are two methods which can be used to impute missing values. One is mean or median imputation and other one is random sample imputation. When there are outliers in the dataset, we should use median imputation. So, we will use median imputation because median imputation is robust to outliers.

* We will impute missing values with the appropriate statistical measures of the data, in this case median. Imputation should be done over the training set, and then propagated to the test set. It means that the statistical measures to be used to fill missing values both in train and test set, should be extracted from the train set only. This is to avoid overfitting.
"""

#impute missing values in X_train and X_test with respective column median in X_train

for df1 in [X_train, X_test]:
  for col in numerical:
    col_median = X_train[col].median()
    df1[col].fillna(col_median, inplace = True)

#check again missing values in numerical variables in X_train

X_train[numerical].isnull().sum()

#check missing values in  numerical variables in X_test

X_test[numerical].isnull().sum()

"""Now, we can see that there are no missing values in the numerical columns of training and test set

**Engineering missing values in categorical variables**
"""

#print percentage of missing values in the categorical variables in training set

X_train[categorical].isnull().mean()

#print categorical variables with missing data

for col in categorical:
  if X_train[col].isnull().mean()>0:
    print(col, (X_train[col].isnull().mean()))

#impute mising categoricak variables with most frequent values

for df2 in [X_train, X_test]:
  df2['WindGustDir'].fillna(X_train['WindGustDir'].mode()[0],inplace=True)
  df2['WindDir9am'].fillna(X_train['WindDir9am'].mode()[0],inplace=True)
  df2['WindDir3pm'].fillna(X_train['WindDir3pm'].mode()[0],inplace=True)
  df2['RainToday'].fillna(X_train['RainToday'].mode()[0],inplace=True)

#now check the missing values

X_test[categorical].isnull().sum()

"""Finally checking the missing values in X_train & X_test"""

#checking the missing values in Test data

X_test.isnull().sum()

#checking the missing values in Train data

X_train.isnull().sum()

"""Observation - There are no missing values in test and train data

**Engineering outliers in numerical variables**

As we have seen that the Rainfall, Evaporation,WindSpeed9am and WindSpeed3pm contains outliers
"""

def max_value(df3,variable,top):
  return np.where(df3[variable]>top, top,df3[variable])

for df3 in [X_train, X_test]:
  df3['Rainfall'] = max_value(df3,'Rainfall',3.2)
  df3['Evaporation'] = max_value(df3,'Evaporation',21.8)
  df3['WindSpeed9am'] = max_value(df3,'WindSpeed9am',55)
  df3['WindSpeed3pm'] = max_value(df3,'WindSpeed3pm',57)

X_train.Rainfall.max(),X_test.Rainfall.max()

X_train.Evaporation.max(),X_test.Evaporation.max()

X_train.WindSpeed9am.max(), X_test.WindSpeed9am.max()

X_train.WindSpeed3pm.max(), X_test.WindSpeed3pm.max()

X_train[numerical].describe()

"""We can now see that the outliers in Rinafall, Evaporation, WindSpeed9am, and WindSpeed3pm columns are capped

**Encode categorical values**
"""

#print categorical values

categorical

X_train[categorical].head()

#encode RainToday variable
# !pip install category_encoders
# import category_encoders as ce

# encoder = ce.BinaryEncoder(cols=['RainToday'])

# X_train = encoder.fit_transform(X_train)

# X_test = encoder.transform(X_test)

X_train['RainToday'] = X_train['RainToday'].map({'Yes':1,'No':0})

X_train.head()

X_train.dtypes

"""We can see two additional variables RainToday_0 and RainToday_1 are created from RainToday variable"""

X_train = pd.concat([X_train[numerical],X_train[['RainToday']], pd.get_dummies(X_train.Location,prefix='Location', prefix_sep='_'),pd.get_dummies(X_train.WindGustDir,prefix='WindGustDir', prefix_sep='_'),pd.get_dummies(X_train.WindDir9am,prefix='WindDir9am', prefix_sep='_'),pd.get_dummies(X_train.WindDir3pm,prefix='WindDir3pm', prefix_sep='_')], axis=1)

X_train.head()

X_train.dtypes.nunique()

X_test['RainToday'] = X_test['RainToday'].map({'Yes':1,'No':0})

"""Similarly we will do it for X_test testing set"""

X_test = pd.concat([X_test[numerical], X_test[['RainToday']],
                     pd.get_dummies(X_test.Location,prefix='Location', prefix_sep='_'),
                     pd.get_dummies(X_test.WindGustDir,prefix='WindGustDir', prefix_sep='_'),
                     pd.get_dummies(X_test.WindDir9am,prefix='WindDir9am', prefix_sep='_'),
                     pd.get_dummies(X_test.WindDir3pm,prefix='WindDir3pm', prefix_sep='_')], axis=1)

X_test.head()

print(X_test.shape)
print(X_test.shape)

"""We now have training and testing set ready for model building. Before that, we should map all the feature variables onto the same scale. It is called feature scaling. I will do it as follows.

# **11. Feature Scaling**
"""

X_train.describe()

cols = X_train.columns

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

X_train = scaler.fit_transform(X_train)

X_test = scaler.transform(X_test)

X_train = pd.DataFrame(X_train, columns = [cols])

X_test = pd.DataFrame(X_test, columns=[cols])

X_train.describe()

"""We now have X_train dataset ready to be fed into the Logistic Regression classifier. I will do it as follows.

# **12.** **Model Training**
"""

from sklearn.linear_model import LogisticRegression

#instantiate the model
logreg = LogisticRegression(solver='liblinear',random_state=0)

#fit the model
logreg.fit(X_train, y_train)

# save the model to disk
filename = 'logreg.pkl'
pickle.dump(logreg, open(filename, 'wb'))

"""# **13. Predict Results**"""

y_pred_test = logreg.predict(X_test)

y_pred_test

"""predict_proba method

* **predict_proba** method gives the probabilities for the target variable(0 and 1) in this case, in array form.

* 0 is for probability of no rain and 1 is for probability of rain
"""

# probability of getting output as 0 - no rain

logreg.predict_proba(X_test)[:,0]

#probability of getting output as 1 - rain

logreg.predict_proba(X_test)[:,1]

"""# **14. Check accuracy score**"""

from sklearn.metrics import accuracy_score

print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))

"""As we can see y_test in the known values and y_pred_test are the predicted values so checked the accuracy which comes to be 85%

Compare the train-set and test-set accuracy
"""

y_pred_train = logreg.predict(X_train)

y_pred_train

print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))

"""Check for overfitting and underfitting"""

print('Training set score: {:.4f}'.format(logreg.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(logreg.score(X_test, y_test)))

"""In Logistic Regression, we use default value of C = 1. It provides good performance with approximately 85% accuracy on both the training and the test set. But the model performance on both the training and test set are very comparable. It is likely the case of underfitting.

We will increase C and fit a more flexible model.
"""

#fit the Logistic Regression model with C=100

#instantiate the model
logreg100 = LogisticRegression(C=100,solver='liblinear',random_state=0)

#fit the model
logreg100.fit(X_train,y_train)

# print the scores on training and test set

print('Training set score: {:.4f}'.format(logreg100.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(logreg100.score(X_test, y_test)))

"""We can see that, C=100 results in higher test set accuracy and also a slightly increased training set accuracy. So, we can conclude that a more complex model should perform better.

Now, I will investigate, what happens if we use more regularized model than the default value of C=1, by setting C=0.01.
"""

# fit the Logsitic Regression model with C=001

# instantiate the model
logreg001 = LogisticRegression(C=0.01, solver='liblinear', random_state=0)


# fit the model
logreg001.fit(X_train, y_train)

# print the scores on training and test set

print('Training set score: {:.4f}'.format(logreg001.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(logreg001.score(X_test, y_test)))

"""So, after using more regularized model by setting C=0.01, then both the test and train set accuracy decreases relative to the default parameters.

**Compare model accuracy with null accuracy**
* So, the model accuracy is 0.8501.  
* We must compare it with the null accuracy.
* Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.

So, we should first check the class distribution in the test set.
"""

#check the class distribution in test set

y_test.value_counts()

"""We can see that the occurences of most frequent class is 22726. So, we can calculate null accuracy by dividing 22726 by total number of occurences."""

#check the null accuracy score

null_accuracy = ((22726)/(22726+6366))

print('Null accuracy score: {0:0.4f}'.format(null_accuracy))

"""**Interpretation**
* We can see that our model accuracy score is **0.8488** but null accuracy score is 0.7812.
* So, we can conclude that our Logistic Regression model is doing a very good job in predicting the class labels.

* But, it does not give the underlying distribution of values. Also, it does not tell anything about the type of errors our classifer is making.

* We have another tool called Confusion matrix that comes to our rescue

# **15. Confusion Matrix**
"""

# print the confusion matrix

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_test)

print('Confusion matrix\n\n',cm)

print('\nTrue Positives(TP) = ',cm[0,0])

print('\nTrue Negatives(TP) = ',cm[1,1])

print('\nFalse Positives(TP) = ',cm[0,1])

print('\nFalse Negatives(TP) = ',cm[1,0])

"""The confusion matrix shows 21543 + 3139 = 24177 correct predictions and 3227 + 1183 = 4262 incorrect predictions.

In this case, we have

* True Positives (Actual Positive:1 and Predict Positive:1) - 21543
* True Negatives (Actual Negative:0 and Predict Negative:0) - 3139
* False Positives (Actual Negative:0 but Predict Positive:1) - 1183 (Type I error)
* False Negatives (Actual Positive:1 but Predict Negative:0) - 3227 (Type II error)
"""

# visualize confusion matrix with seaborn heatmap

cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],
                                 index=['Predict Positive:1', 'Predict Negative:0'])

sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')

"""# **16. Classification Metrics**

**Classificaton Report**
"""

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_test))

"""**Classification Accuracy**"""

TP = cm[0,0]
TN = cm[1,1]
FP = cm[0,1]
FN = cm[1,0]

#print classificaiton accuracy

classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)

print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))

"""**Classification Error**"""

# print classification error

classification_error = (FP + FN) / float(TP + TN + FP + FN)

print('Classification error : {0:0.4f}'.format(classification_error))

"""**Comparing Different algorithms and their accuracy**

***
**1. Logistic Regression**
***
"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X_train,y_train)
predictions = lr.predict(X_test)
print(confusion_matrix(y_test, predictions))
print(classification_report(y_test, predictions))
print(accuracy_score(y_test, predictions))

"""***
**2. Decision Trees**
***
"""

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(X_train,y_train)
predictions = dt.predict(X_test)
print(confusion_matrix(y_test, predictions))
print(classification_report(y_test, predictions))
print(accuracy_score(y_test, predictions))



"""**Hence we conclude that on comparing the there Alogithms Logistic Regression proves to be most accurate**

# **17. Model evaluation and Improvement**

In this section, We will employ k-fold cross validation technique to improve the model performance.

***
**k-Fold Cross Validation**
***
"""

# Applying 5-Fold Cross Validation

from sklearn.model_selection import cross_val_score

scores = cross_val_score(logreg, X_train, y_train, cv = 5, scoring='accuracy')

print('Cross-validation scores:{}'.format(scores))

"""We can summarize the cross-validation accuracy by calculating its mean"""

# compute Average cross-validation score

print('Average cross-validation score: {:.4f}'.format(scores.mean()))

"""Our, original model score is found to be 0.8488. The average cross-validation score is 0.8481. So, we can conclude that cross-validation does not result in performance improvement.

# **18. Results and Conclusion**

1. The logistic regression model accuracy score is 0.8488. So, the model does a very good job in predicting whether or not it will rain tomorrow in Australia.

2. Small number of observations predict that there will be rain tomorrow. Majority of observations predict that there will be no rain tomorrow.

3. The model shows no signs of overfitting.

4. Increasing the value of C results in higher test set accuracy and also a slightly increased training set accuracy. So, we can conclude that a more complex model should perform better.

5. Our, original model score is found to be 0.8488. The average cross-validation score is 0.8481. So, we can conclude that cross-validation does not result in performance improvement.
"""